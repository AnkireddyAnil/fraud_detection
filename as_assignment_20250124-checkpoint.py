# -*- coding: utf-8 -*-
"""AS_ASSIGNMENT_20250124

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zKMN-vMoV7tl2Fdy8Qc_t3mxn0Z_VsYO

# **Import Libraries**
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns

"""# **Load and Explore the Dataset**"""

# Load dataset
file_path = "/content/PS_20174392719_1491204439457_log.csv"
data = pd.read_csv(file_path)

# Display basic information
print(data.info())
print(data.head())

# Check for missing values
print(data.isnull().sum())

# Quick statistics of numerical columns
print(data.describe())

"""# **Preprocessing the Data**

***Drop irrelevant columns***
"""

data = data.drop(['oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'nameOrig', 'nameDest'], axis=1)

"""***Handle categorical data***"""

data = pd.get_dummies(data, columns=['type'], drop_first=True)

"""***Handle class imbalance***"""

from imblearn.over_sampling import SMOTE

X = data.drop(['isFraud'], axis=1)
y = data['isFraud']

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Verify class distribution
print(y_resampled.value_counts())

"""***Scale the features***"""

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_resampled)

"""# **Train-Test Split**"""

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_resampled, test_size=0.3, random_state=42, stratify=y_resampled)

print(f"Training set size: {X_train.shape}")
print(f"Test set size: {X_test.shape}")

"""# **Train a Machine Learning Model**

***Logistic Regression Model***
"""

from sklearn.linear_model import LogisticRegression

# Initialize the Logistic Regression model
model = LogisticRegression(max_iter=1000, random_state=42)

# Train the model on the training set
model.fit(X_train, y_train)

"""# **Model Evaluation**

***Predictions and Confusion Matrix***
"""

# Make predictions on the test set
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)[:, 1]

# Print the confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

"""***ROC-AUC Score and Curve***"""

# Compute ROC-AUC score
roc_auc = roc_auc_score(y_test, y_pred_proba)
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f"ROC Curve (AUC = {roc_auc:.2f})")
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

"""***Precision-Recall Curve***"""

# Compute Precision-Recall AUC
precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
pr_auc = auc(recall, precision)

# Plot Precision-Recall curve
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, label=f"Precision-Recall Curve (AUC = {pr_auc:.2f})")
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend()
plt.show()

"""# **Prepare the Data for Tableau**

***Export Preprocessed Dataset***
"""

print(f"Number of unique rows in X_scaled: {len(pd.DataFrame(X_scaled).drop_duplicates())}")

print(f"Indexes in data: {data.index}")
print(f"Indexes in X_scaled: {len(X_scaled)}")

X_scaled = X_scaled[:len(data)]  # Truncate X_scaled to match the original dataset

print(f"Length of data after alignment: {len(data)}")
print(f"Length of X_scaled after alignment: {len(X_scaled)}")

# Add predictions to the dataset
data['isFraud_pred'] = model.predict(X_scaled)
data['fraud_probability'] = model.predict_proba(X_scaled)[:, 1]

# Save the updated dataset
data.to_csv('fraud_detection_results.csv', index=False)

"""***Model Metrics (Confusion Matrix and Precision-Recall Curve)***"""

# Confusion matrix data
cm = confusion_matrix(y_test, y_pred)
cm_df = pd.DataFrame(cm, columns=['Predicted Negative', 'Predicted Positive'], index=['Actual Negative', 'Actual Positive'])
cm_df.to_csv('confusion_matrix.csv')

# Precision-recall data
precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
pr_df = pd.DataFrame({'Precision': precision, 'Recall': recall})
pr_df.to_csv('precision_recall_curve.csv')